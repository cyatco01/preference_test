{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./decode1/lib/python3.12/site-packages (4.46.3)\n",
      "Requirement already satisfied: datasets in ./decode1/lib/python3.12/site-packages (3.1.0)\n",
      "Requirement already satisfied: accelerate in ./decode1/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: filelock in ./decode1/lib/python3.12/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./decode1/lib/python3.12/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./decode1/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./decode1/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./decode1/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./decode1/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./decode1/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./decode1/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./decode1/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./decode1/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./decode1/lib/python3.12/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./decode1/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./decode1/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in ./decode1/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./decode1/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in ./decode1/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in ./decode1/lib/python3.12/site-packages (from datasets) (3.11.9)\n",
      "Requirement already satisfied: psutil in ./decode1/lib/python3.12/site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./decode1/lib/python3.12/site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./decode1/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./decode1/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./decode1/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./decode1/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./decode1/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./decode1/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./decode1/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./decode1/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./decode1/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./decode1/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./decode1/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./decode1/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: sympy in ./decode1/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./decode1/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./decode1/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./decode1/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./decode1/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./decode1/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./decode1/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./decode1/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./decode1/lib/python3.12/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Overview  Sentiment_Score  \\\n",
      "0  Two imprisoned men bond over a number of years...        -0.300000   \n",
      "1  An organized crime dynasty's aging patriarch t...         0.000000   \n",
      "2  When the menace known as the Joker wreaks havo...         0.333333   \n",
      "3  The early life and career of Vito Corleone in ...         0.118182   \n",
      "4  A jury holdout attempts to prevent a miscarria...         0.000000   \n",
      "\n",
      "   Valence_Score  Arousal_Score  Dominance_Score     Tempo  \n",
      "0       0.564455       0.362636         0.485636  0.018750  \n",
      "1       0.534400       0.532500         0.667500  0.000000  \n",
      "2       0.497643       0.602500         0.586929  0.066667  \n",
      "3       0.684500       0.545200         0.602200  0.014336  \n",
      "4       0.477333       0.558167         0.637167  0.000000  \n"
     ]
    }
   ],
   "source": [
    "file_path = '/Users/carolynyatco/decode_ai/get_weights/movies_training.csv'\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load CSV data\n",
    "\n",
    "# Normalize sentiment scores\n",
    "scaler = MinMaxScaler()\n",
    "features = [\"Sentiment_Score\", \"Valence_Score\", \"Arousal_Score\", \"Dominance_Score\", \"Tempo\"]\n",
    "df[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "# Define user weights for training\n",
    "user_weights = {\n",
    "    \"Sentiment_Score\": 0.25,\n",
    "    \"Valence_Score\": 0.2,\n",
    "    \"Arousal_Score\": 0.2,\n",
    "    \"Dominance_Score\": 0.15,\n",
    "    \"Tempo\": 0.2\n",
    "}\n",
    "\n",
    "# Format training prompts\n",
    "def format_training_prompt(row, user_weights):\n",
    "    # Apply user weights to sentiment scores\n",
    "    weighted_features = {feature: row[feature] * weight for feature, weight in user_weights.items()}\n",
    "    weighted_summary = \", \".join([f\"{key}: {value:.2f}\" for key, value in weighted_features.items()])\n",
    "    \n",
    "    # Construct the training prompt\n",
    "    return (\n",
    "        f\"User Preferences: {weighted_summary}\\n\"\n",
    "        f\"Generate a creative commercial storyboard idea based on these preferences.\\n\"\n",
    "        f\"Storyboard (Training Target): {row['Overview']}\"  # Overview is the target during training\n",
    "    )\n",
    "\n",
    "# Apply prompt formatting to the dataset\n",
    "df[\"prompt\"] = df.apply(lambda row: format_training_prompt(row, user_weights), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=256):\n",
    "        self.prompts = df[\"prompt\"].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.prompts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoded = self.tokenizer(\n",
    "            self.prompts[idx],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoded[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encoded[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": encoded[\"input_ids\"].squeeze()\n",
    "        }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decode1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
